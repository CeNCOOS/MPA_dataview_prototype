{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import datetime as dt\n",
    "\n",
    "import os\n",
    "import re\n",
    "import urllib.request\n",
    "from urllib.request import Request, urlopen, urlretrieve\n",
    "from bs4 import BeautifulSoup\n",
    "from glob import glob\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pull HTML index file and make it into a list\n",
    "# (modified from https://stackoverflow.com/questions/11023530/python-to-list-http-files-and-directories)\n",
    "# filter list by .hdf files and extract those filenames\n",
    "# open each of these .hdf files with xarray via urlretrieve()\n",
    "\n",
    "def get_data_urls(url):\n",
    "    url = url.replace(\" \",\"%20\")\n",
    "    req = Request(url)\n",
    "    a = urlopen(req).read()\n",
    "    soup = BeautifulSoup(a, 'html.parser')\n",
    "    x = (soup.find_all('a'))\n",
    "    text_list = []\n",
    "    for i in x:\n",
    "        file_name = i.extract().get_text()\n",
    "        url_new = url + file_name\n",
    "        url_new = url_new.replace(\" \",\"%20\")\n",
    "        text_list.append(url_new)\n",
    "    datafile_list = list(filter(re.compile(\".*hdf\").match, text_list)) # Read Note\n",
    "  \n",
    "    return(datafile_list)\n",
    "\n",
    "        \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to open a .hdf datafile from the Wimsoft site by running it through urlretrieve()\n",
    "\n",
    "def pull_hdf(url):\n",
    "    local_filename, headers = urllib.request.urlretrieve(url)\n",
    "    return(xr.open_dataset(local_filename))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to clean up the .hdf datafile from the Wimsoft site \n",
    "\n",
    "def clean_hdf(dataset, year, doy):\n",
    "    var_name = str('sst_' + str(year) + doy)\n",
    "    \n",
    "    # add lat/long coordinates\n",
    "    dataset['fakeDim0'] = sst_coords['Latitude'].values[:,0]\n",
    "    dataset['fakeDim1'] = sst_coords['Longitude'].values[0,:]\n",
    "    \n",
    "    # rename lat, long, and sst variables\n",
    "    ds = dataset.rename({'fakeDim0': 'lat',\n",
    "                         'fakeDim1': 'lon',\n",
    "                         var_name: 'sst'})\n",
    "    \n",
    "    # create time and add it as a dimension to the hdf\n",
    "    date = dt.datetime(int(year), 1, 1) + dt.timedelta(int(doy) -1)\n",
    "    ds.coords['time'] = date\n",
    "    ds['sst'] = ds['sst'].assign_coords(time = date)\n",
    "    \n",
    "    # filter and convert sst values based on documentation\n",
    "    # data should be unsigned ints but are imported as signed\n",
    "    # to fix, negative values should have a constant 256 added to them\n",
    "    # then remove values of 0 and 255, which are invalid\n",
    "    ds = (ds.where(ds['sst'] > 0, ds['sst'] + 256)\n",
    "           .where((ds['sst'] != 0) & (ds['sst'] != 1) & (ds['sst'] != 255))\n",
    "         )\n",
    "    \n",
    "    # convert sst pixel values to degC\n",
    "    ds['sst'] = 0.15*ds['sst'] - 3.0\n",
    "\n",
    "    \n",
    "    return(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# technically, should just be able to open this directly from Wimsoft but my connection is slow af\n",
    "# so I'm just going to load it from local disk instead  ¯\\_(ツ)_/¯\n",
    "\n",
    "# sst_coords = pull_hdf(\"http://wimsoft.com/CAL/files/cal_aco_3840_Latitude_Longitude.hdf\")\n",
    "\n",
    "sst_coords = xr.open_dataset(\"../../../Raw_Data/Wimsoft_SST/cal_aco_3840_Latitude_Longitude.hdf\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found 365 data files for 2015\n",
      "concatenating 2015_001\n",
      "concatenating 2015_002\n",
      "concatenating 2015_003\n",
      "concatenating 2015_004\n",
      "concatenating 2015_005\n",
      "concatenating 2015_006\n",
      "concatenating 2015_007\n",
      "concatenating 2015_008\n",
      "concatenating 2015_009\n",
      "concatenating 2015_010\n",
      "concatenating 2015_011\n",
      "concatenating 2015_012\n",
      "concatenating 2015_013\n",
      "concatenating 2015_014\n",
      "concatenating 2015_015\n",
      "concatenating 2015_016\n",
      "concatenating 2015_017\n",
      "concatenating 2015_018\n",
      "concatenating 2015_019\n",
      "concatenating 2015_020\n",
      "concatenating 2015_021\n",
      "concatenating 2015_022\n",
      "concatenating 2015_023\n",
      "concatenating 2015_024\n",
      "concatenating 2015_025\n",
      "concatenating 2015_026\n",
      "concatenating 2015_027\n",
      "concatenating 2015_028\n",
      "concatenating 2015_029\n",
      "concatenating 2015_030\n",
      "concatenating 2015_031\n",
      "concatenating 2015_032\n",
      "concatenating 2015_033\n",
      "concatenating 2015_034\n",
      "concatenating 2015_035\n",
      "concatenating 2015_036\n",
      "concatenating 2015_037\n",
      "concatenating 2015_038\n",
      "concatenating 2015_039\n",
      "concatenating 2015_040\n",
      "concatenating 2015_041\n",
      "concatenating 2015_042\n",
      "concatenating 2015_043\n",
      "concatenating 2015_044\n",
      "concatenating 2015_045\n",
      "concatenating 2015_046\n",
      "concatenating 2015_047\n",
      "concatenating 2015_048\n",
      "concatenating 2015_049\n",
      "concatenating 2015_050\n",
      "concatenating 2015_051\n",
      "concatenating 2015_052\n",
      "concatenating 2015_053\n",
      "concatenating 2015_054\n",
      "concatenating 2015_055\n",
      "concatenating 2015_056\n",
      "concatenating 2015_057\n",
      "concatenating 2015_058\n",
      "concatenating 2015_059\n",
      "concatenating 2015_060\n",
      "concatenating 2015_061\n",
      "concatenating 2015_062\n",
      "concatenating 2015_063\n",
      "concatenating 2015_064\n",
      "concatenating 2015_065\n",
      "concatenating 2015_066\n",
      "concatenating 2015_067\n",
      "concatenating 2015_068\n",
      "concatenating 2015_069\n",
      "concatenating 2015_070\n",
      "concatenating 2015_071\n",
      "concatenating 2015_072\n",
      "concatenating 2015_073\n",
      "concatenating 2015_074\n",
      "concatenating 2015_075\n",
      "concatenating 2015_076\n",
      "concatenating 2015_077\n",
      "concatenating 2015_078\n",
      "concatenating 2015_079\n",
      "concatenating 2015_080\n",
      "concatenating 2015_081\n",
      "concatenating 2015_082\n",
      "concatenating 2015_083\n",
      "concatenating 2015_084\n",
      "concatenating 2015_085\n",
      "concatenating 2015_086\n",
      "concatenating 2015_087\n",
      "concatenating 2015_088\n",
      "concatenating 2015_089\n",
      "concatenating 2015_090\n",
      "concatenating 2015_091\n",
      "concatenating 2015_092\n",
      "concatenating 2015_093\n",
      "concatenating 2015_094\n",
      "concatenating 2015_095\n",
      "concatenating 2015_096\n",
      "concatenating 2015_097\n",
      "concatenating 2015_098\n",
      "concatenating 2015_099\n",
      "concatenating 2015_100\n",
      "concatenating 2015_101\n",
      "concatenating 2015_102\n",
      "concatenating 2015_103\n",
      "concatenating 2015_104\n",
      "concatenating 2015_105\n",
      "concatenating 2015_106\n",
      "concatenating 2015_107\n",
      "concatenating 2015_108\n",
      "concatenating 2015_109\n",
      "concatenating 2015_110\n",
      "concatenating 2015_111\n",
      "concatenating 2015_112\n",
      "concatenating 2015_113\n",
      "concatenating 2015_114\n",
      "concatenating 2015_115\n",
      "concatenating 2015_116\n",
      "concatenating 2015_117\n",
      "concatenating 2015_118\n",
      "concatenating 2015_119\n",
      "concatenating 2015_120\n",
      "concatenating 2015_121\n",
      "concatenating 2015_122\n",
      "concatenating 2015_123\n",
      "concatenating 2015_124\n",
      "concatenating 2015_125\n",
      "concatenating 2015_126\n",
      "concatenating 2015_127\n",
      "concatenating 2015_128\n",
      "concatenating 2015_129\n",
      "concatenating 2015_130\n",
      "concatenating 2015_131\n",
      "concatenating 2015_132\n",
      "concatenating 2015_133\n",
      "concatenating 2015_134\n",
      "concatenating 2015_135\n",
      "concatenating 2015_136\n",
      "concatenating 2015_137\n",
      "concatenating 2015_138\n",
      "concatenating 2015_139\n",
      "concatenating 2015_140\n",
      "concatenating 2015_141\n",
      "concatenating 2015_142\n",
      "concatenating 2015_143\n",
      "concatenating 2015_144\n",
      "concatenating 2015_145\n",
      "concatenating 2015_146\n",
      "concatenating 2015_147\n",
      "concatenating 2015_148\n",
      "concatenating 2015_149\n",
      "concatenating 2015_150\n",
      "concatenating 2015_151\n",
      "concatenating 2015_152\n",
      "concatenating 2015_153\n",
      "concatenating 2015_154\n",
      "concatenating 2015_155\n",
      "concatenating 2015_156\n",
      "concatenating 2015_157\n",
      "concatenating 2015_158\n",
      "concatenating 2015_159\n",
      "concatenating 2015_160\n",
      "concatenating 2015_161\n",
      "concatenating 2015_162\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-b0a2fb6de209>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mdoy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'_'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mhdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpull_hdf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0mds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclean_hdf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myear\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdoy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mj\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-8d36dab83fd1>\u001b[0m in \u001b[0;36mpull_hdf\u001b[0;34m(url)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mpull_hdf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mlocal_filename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0murllib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murlretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocal_filename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/mpa_env/lib/python3.7/urllib/request.py\u001b[0m in \u001b[0;36murlretrieve\u001b[0;34m(url, filename, reporthook, data)\u001b[0m\n\u001b[1;32m    274\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 276\u001b[0;31m                 \u001b[0mblock\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    277\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m                     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/mpa_env/lib/python3.7/http/client.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    455\u001b[0m             \u001b[0;31m# Amount is given, implement using readinto\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m             \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbytearray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m             \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadinto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mmemoryview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtobytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/mpa_env/lib/python3.7/http/client.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    499\u001b[0m         \u001b[0;31m# connection, and the user is reading more bytes than will be provided\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    500\u001b[0m         \u001b[0;31m# (for example, reading in 1k chunks)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 501\u001b[0;31m         \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadinto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    502\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m             \u001b[0;31m# Ideally, we would raise IncompleteRead if the content-length\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/mpa_env/lib/python3.7/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    587\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 589\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    590\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    591\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/mpa_env/lib/python3.7/ssl.py\u001b[0m in \u001b[0;36mrecv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1069\u001b[0m                   \u001b[0;34m\"non-zero flags not allowed in calls to recv_into() on %s\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1070\u001b[0m                   self.__class__)\n\u001b[0;32m-> 1071\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1072\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1073\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/mpa_env/lib/python3.7/ssl.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m    927\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbuffer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 929\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    930\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Download all the SST data, write them to netCDFs by year\n",
    "\n",
    "# year_list = [str(yr) for yr in range(2000, 2021)]\n",
    "\n",
    "year_list = [str(yr) for yr in range(2015, 2020)]\n",
    "\n",
    "for i, year in enumerate(year_list):\n",
    "    index_url = str('https://www.wimsoft.com/CAL/'+ year + '/M' + year + '_sst_day/')\n",
    "    url_list = get_data_urls(index_url)\n",
    "    print('found {} data files for {}'.format(len(url_list), year))\n",
    "    for j, url in enumerate(url_list): \n",
    "        doy = url.split('_')[2][-3:]   \n",
    "        hdf = pull_hdf(url)\n",
    "        ds = clean_hdf(hdf, year, doy)        \n",
    "        if j == 0:  \n",
    "            ds_all = ds\n",
    "        else:\n",
    "            ds_all = xr.concat([ds_all, ds], dim = 'time')\n",
    "        print('concatenating {}_{}'.format(year, doy))\n",
    "            \n",
    "    ds_all = ds_all.sortby('time')\n",
    "    print('writing year {} to netcdf'.format(year))\n",
    "    ds_all.to_netcdf('SST_winsoft_dataset/merged_sst_' + str(year) + '2.nc', mode = 'w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sst['fakeDim0'] = sst_coords['Latitude'].values[:,0]\n",
    "test_sst['fakeDim1'] = sst_coords['Longitude'].values[0,:]\n",
    "\n",
    "# test_sst.rename({fakeDim0': 'lat', 'fakeDim1': 'lon',})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'https://www.wimsoft.com/CAL/2011/M2011_sst_day/M2011001_sst_comp.hdf'.split('_')[2][-3:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sst_2011 = pull_hdf('https://www.wimsoft.com/CAL/2011/M2011_sst_day/M2011001_sst_comp.hdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sst_2012 = pull_hdf('https://www.wimsoft.com/CAL/2012/M2012_sst_day/M2012001_sst_comp.hdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sst_2013 = pull_hdf('https://www.wimsoft.com/CAL/2013/M2013_sst_day/M2013001_sst_comp.hdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'https://www.wimsoft.com/CAL/2013/M2013_sst_day/M2013001_sst_comp.hdf'.split('_')[2][-3:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
